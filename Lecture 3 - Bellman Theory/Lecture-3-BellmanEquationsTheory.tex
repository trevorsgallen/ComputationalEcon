\documentclass{beamer}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usepackage{tikz}
\usetheme{default}
%\usecolortheme{seahorse}
\usepackage{default}

  \setbeamertemplate{footline}[page number]
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{frametitle}[default][center]
\setbeamerfont{frametitle}{shape=\scshape}

\usepackage{color}

{\title{\textsc{Numerical Methods-Lecture III: Bellman Equations: Theory}}
\author{Trevor Gallen}
\date{}

\begin{document}


\begin{frame}
\titlepage
\end{frame}

\begin{frame}
\frametitle[alignment=center]{Preliminaries}
\begin{itemize}
\item I assume you have seen Bellman equations before
\bigskip
\item Seeing Bellman equations before is unnecessary
\bigskip
\item I will introduce as if you have forgotten everything
\bigskip
\item I leave the technical requirements to chapters 4 and 9 of Stokey \& Lucas with Prescott, (RMED).
\bigskip
\item Most of the problems we write down will be well-conditioned
\bigskip
\item This class : DP math :: rocket engineering : physics
\bigskip
\begin{itemize}
\item<2-> No need to know theory, but can blow up in your face
\bigskip
\end{itemize}
\item<3-> With that shallow warning, we'll be learning Monkey Bellmans
\end{itemize}
\end{frame}

\begin{frame}
\frametitle[alignment=center]{Sequence Problem}
\begin{itemize}
\item We can formulate a number of very interesting problems as:
$$\underset{\left\{x_{t+1}\right\}_{t=0}^\infty}{\max}\sum_{t=0}^\infty \beta^t F(x_t,x_{t+1})$$
\ \\
s.t. $x_{t+1}\in\Gamma(x_t),\ \ \ t=0,1,2,...$
$$x_0\in X\ \ \text{is given}.$$
\item<2-> Too abstract for an engineer.  What is this saying?  Translate it.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle[alignment=center]{Sequence Problem: Pieces}
\begin{itemize}
\item $F(\cdot,\cdot)$ is something we're trying to maximize
\bigskip
\item $x_{t+1}$ is the thing we can control
\bigskip
\item $F$ is influenced by:
\bigskip
\begin{itemize}
\item  Something we control right now: $x_{t+1}$  
\bigskip
\item Something that we don't control right now: $x_t$ 
\bigskip
\item But yesterday, we controlled it (except in first period)
\end{itemize}
\bigskip
\item Our ability to control $x_{t+1}$ is governed by $x_t$ (via $\Gamma$)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle[alignment=center]{Generality? Example 1: NCG}
We get utility from consumption.  Consumption is constrained by capital.
$$\max\  \text{NPV of \ }U(c_t)\ \ \ s.t. \ \ \  Ak_{t}^\alpha = c_t + i_t,\ \ \ \ \ k_{t+1}=(1-\delta)k_t+i_t$$
\begin{itemize}
\item $U(c_t)$ is something we're trying to maximize
\smallskip
\item $k_{t+1}$ is the thing we can control
\smallskip
\item $F$ is influenced by:
\smallskip
\begin{itemize}
\item  Something we control right now: $k_{t+1}$ (via LOM, $c_t$)  
\smallskip
\item Something that we don't control right now: $k_t$ 
\end{itemize}
\smallskip
\item Our ability to control $k_{t+1}$ is governed by $k_t$, which gives our budget constraint
\end{itemize}
\end{frame}

\begin{frame}
\frametitle[alignment=center]{Generality? Example 2: McCall's Model-I}
\begin{itemize}
\item Search for job
\bigskip
\item Each period, one offer $w$ from bounded wage distribution with CDF $F(w)$
\bigskip
\item Can reject, get $c$
\bigskip
\item Can accept, get $w$ forever
\bigskip
\item Utility is equal to whatever income you get (c or w).
\end{itemize}
\end{frame}

\begin{frame}
\frametitle[alignment=center]{Generality? Example 2: McCall's Model}
$$\max\  \text{NPV of \ }U(c_t)\ \ \ s.t. \ \ \ c_t=\begin{cases}w & \text{if accept w} \\ c & \text{if not accepted}\end{cases}$$\\ 
\begin{table}[htdb!]
\centering
\begin{tabular}{rl} $w_{t+1}=w$ & \text{if accept w}  \\ $w_{t+1}\sim F(w)$ & \text{if not accepted}\end{tabular}
\end{table}
\
\begin{itemize}
\item $U(c_t)$ is something we're trying to maximize
\smallskip
\item We control if $w$ or $c$
\smallskip
\item $F$ is influenced by:
\smallskip
\begin{itemize}
\item Our choice of $c$ vs. $w$ if not yet chosen (memoryless)
\smallskip
\item  Our past choice of $w$ if accepted (no choice)
\end{itemize}
\smallskip
\item Next $w$ is influenced by past w (sometimes)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle[alignment=center]{Generality? Example 3: Firm Investment  }
Firm wants to maximize profit given $A$ and $K$, with profits:
$$a_i\in\{0,1,...,100\}$$
$$Pr(A_{t+1}=a_i|A_t)\ \ given$$ 
$$\pi_t = \begin{cases}-(A_t-K_t)^2  & \text{if no change} \\ -(A_t-K_t^*)^2-C & \text{if change}\end{cases}$$
$$\begin{cases}K_{t+1}=K_t  & \text{if no change} \\ K_{t+1}=K_t^* & \text{if change}\end{cases}$$
Where if change, $K_t^*$ is chosen from the range of $a_i$.  
\end{frame}

\begin{frame}
\frametitle[alignment=center]{The Bellman Equation - I}
\begin{itemize}
\item Starting with a sequence problem:
$$\underset{\left\{x_{t+1}\right\}_{t=0}^\infty}{\max}\sum_{t=0}^\infty \beta^t F(x_t,x_{t+1})$$
\ \\
s.t. $x_{t+1}\in\Gamma(x_t),\ \ \ t=0,1,2,...$
$$x_0\in X\ \ \text{is given}.$$
\item We can define an equation:
$$V(x)=\underset{y\in\Gamma(x)}{\max}\left\{F(x,y)+\beta V(y)\right\}$$
\item Call $x$ the state, $y$ the control, $V$ the value function
\end{itemize}
\end{frame}

\begin{frame}
\frametitle[alignment=center]{The Bellman Equation - II}
$$V(x)=\underset{y\in\Gamma(x)}{\max}\left\{F(x,y)+\beta V(y)\right\}$$
\begin{itemize}
\item What are doing?
\begin{itemize}
\item Want to maximize current and future $F$'s through choice of all future $x$'s
\smallskip
\item Simplify the problem: today, and the problem you wake up with tomorrow
\smallskip
\item Tomorrow, you maximize today, and the next day's problem
\smallskip
\item Define everything recursively: the NPV of happiness if you wake up with $x$ and maximize is utility today plus the NPV of happiness when you wake up with whatever you have left tomorrow
\end{itemize}
\item Call $x$ our state, the thing we wake up with
\smallskip
\item Call $y$ our control, the thing we control
\smallskip
\item Call $\Gamma$ our law of motion
\end{itemize}
\end{frame}

\begin{frame}
\frametitle[alignment=center]{The Bellman Equation - III}
$$V(x_t)=\underset{\left\{y_s\right\}_{s=t}^\infty}{\max}\sum_{s=t}^\infty \beta^{s-t}F(x_s,y_s)$$
Break the first part out:
$$V(x_t)=\underset{\left\{y_s\right\}_{s=t}^\infty}{\max}\left[\beta^{t-t}F(x_t,y_t)+\sum_{s=t+1}^\infty \beta^{s-t}F(x_s,y_s)\right]$$
Break up the optimization and take out a $\beta$:
$$V(x_t)=\underset{y_t}{\max} \left[F(x_t,y_t)+\beta \underset{\left\{y_s\right\}_{s=t+1}^\infty}{\max}\sum_{s=t+1}^\infty \beta^{s-t-1}F(x_s,y_s)\right]$$
 \end{frame}

\begin{frame}
\frametitle[alignment=center]{The Bellman Equation - VI}
$$V(x_t)=\underset{y_t}{\max} \left[F(x_t,y_t)+\beta \underset{\left\{y_s\right\}_{s=t+1}^\infty}{\max}\sum_{s=t+1}^\infty \beta^{s-t-1}F(x_s,y_s)\right]$$
Notice that if we replaced $t$ with $t+1$ in the definition, we would have:
$$V(x_{t+1})=\underset{\left\{y_s\right\}_{s=t+1}^\infty}{\max}\sum_{s=t+1}^\infty \beta^{s-t-1}F(x_s,y_s)$$
Plugging this in:
$$V(x_t)=\underset{y_t}{\max} \left[F(x_t,y_t)+\beta V(x_{t+1})\right]$$
Given an $x_t$, just need a $y_t$, and whatever the value of all the future decisions we make will be.
 \end{frame}


\begin{frame}
\frametitle[alignment=center]{Summing Up}
\begin{itemize}
\item Bellmans are a flexible way of describing a large number of dynamic problems
\bigskip
\item We can write down problems easily
\bigskip
\item Now we want to numerically solve them
\bigskip
\item Next up:  value function iteration (extremely easy and intuitive ways to solve)
\end{itemize}
\end{frame}


\end{document}